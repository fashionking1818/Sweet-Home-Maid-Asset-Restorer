import os
import json
import requests
import base64
import binascii
import urllib3
import concurrent.futures
from tqdm import tqdm
import threading

# ================= âš™ï¸ é…ç½®åŒºåŸŸ =================
LOCAL_CONFIG_DIR = "configs" 
SAVE_IMPORT_ROOT = "imports"  # ç¡®ä¿è¿™ä¸ªåå­—å’Œä½ æˆªå›¾é‡Œçš„æ–‡ä»¶å¤¹åå­—ä¸€æ¨¡ä¸€æ ·

BASE_RES_URL = "https://game.sweet-home-maid.com/r/7LCHDxB8msHV/"
MAX_WORKERS = 8  # çº¯æ–‡æœ¬ä¸‹è½½ï¼Œå¼€å¤§ä¸€ç‚¹æ²¡é—®é¢˜

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Referer": "https://game.sweet-home-maid.com/r/7LCHDxB8msHV/index.html",
}
# ===============================================

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- å…¨å±€å˜é‡ï¼šç”¨äºå­˜å‚¨æœ¬åœ°å·²æœ‰çš„ UUID ---
EXISTING_UUIDS = set()

def decompress_uuid(uuid_str):
    """ Cocos UUID è§£å‹é€»è¾‘ """
    suffix = ""
    base_uuid = uuid_str
    if "@" in uuid_str:
        parts = uuid_str.split("@", 1)
        base_uuid = parts[0]
        suffix = "@" + parts[1]

    real_base = base_uuid
    if len(base_uuid) == 22 or len(base_uuid) == 23:
        temp_uuid = base_uuid[1:] if base_uuid.startswith('_') else base_uuid
        try:
            b64 = temp_uuid[2:].replace('-', '+').replace('_', '/')
            pad = len(b64) % 4
            if pad > 0: b64 += '=' * (4 - pad)
            data = base64.b64decode(b64)
            hex_s = binascii.hexlify(data).decode('utf-8')
            prefix = temp_uuid[:2]
            real_base = f"{prefix}{hex_s[0:6]}-{hex_s[6:10]}-{hex_s[10:14]}-{hex_s[14:18]}-{hex_s[18:]}"
        except:
            pass
            
    return real_base + suffix

def compress_uuid(uuid_str):
    """ ç®€å•çš„å‹ç¼©é€»è¾‘ï¼Œç”¨äºè¾…åŠ©æ¯”å¯¹ï¼ˆå¦‚æœéœ€è¦ï¼‰ """
    # è¿™é‡Œåªåšç®€å•çš„è¿”å›ï¼Œä¸»è¦ä¾é  decompress ç»Ÿä¸€æ¯”å¯¹
    return uuid_str

def scan_local_files():
    """
    æ ¸å¿ƒåŠŸèƒ½ï¼šæ‰«æç¡¬ç›˜ï¼Œå»ºç«‹å·²å­˜åœ¨æ–‡ä»¶çš„ç´¢å¼•
    """
    print(f"[-] æ­£åœ¨æ‰«ææœ¬åœ°æ–‡ä»¶: {os.path.abspath(SAVE_IMPORT_ROOT)}")
    count = 0
    if not os.path.exists(SAVE_IMPORT_ROOT):
        return
        
    for root, dirs, files in os.walk(SAVE_IMPORT_ROOT):
        for file in files:
            if file.endswith(".json"):
                # æ–‡ä»¶åé€šå¸¸æ˜¯: uuid.ver.json æˆ– uuid.json
                # æˆ‘ä»¬å–ç¬¬ä¸€ä¸ªç‚¹ä¹‹å‰çš„éƒ¨åˆ†ä½œä¸º Key
                # ä¾‹å¦‚: "0a1b2c3d-....f9941.json" -> "0a1b2c3d-..."
                try:
                    # å‡è®¾æ–‡ä»¶åæ ¼å¼ä¸º UUID.HASH.jsonï¼Œå– UUID éƒ¨åˆ†
                    # æ³¨æ„ï¼šæœ‰äº› UUID æœ¬èº«åŒ…å« '-'ï¼Œæ‰€ä»¥ä¸èƒ½ç®€å•ç”¨ split
                    # æœ€ç¨³å¦¥çš„æ–¹æ³•ï¼šå»æ‰æœ€åçš„ .jsonï¼Œå†å»æ‰ .ver (å¦‚æœå­˜åœ¨)
                    name_part = file.replace(".json", "")
                    
                    # å°è¯•åˆ†ç¦»ç‰ˆæœ¬å·ï¼ˆé€šå¸¸ UUID å’Œç‰ˆæœ¬å·ä¸­é—´æœ‰ç‚¹ï¼‰
                    # å¦‚æœ UUID æ˜¯ 36 ä½ (é•¿) æˆ– 22 ä½ (çŸ­)ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•æå–
                    if "." in name_part:
                        # å‡è®¾æœ€åä¸€æ®µæ˜¯ç‰ˆæœ¬å·
                        candidate_uuid = name_part.rsplit(".", 1)[0]
                        EXISTING_UUIDS.add(candidate_uuid)
                    
                    # åŒæ—¶ä¹ŸæŠŠæ•´ä¸ªæ–‡ä»¶åï¼ˆä¸å«jsonï¼‰åŠ è¿›å»ï¼Œä»¥é˜²ä¸‡ä¸€
                    EXISTING_UUIDS.add(name_part)
                    count += 1
                except:
                    pass
    
    print(f"[-] ç´¢å¼•å»ºç«‹å®Œæˆï¼æœ¬åœ°å…±æœ‰ {count} ä¸ªæ–‡ä»¶ (å«å˜ä½“)ã€‚")

def download_file(url, path):
    try:
        # æœ€åä¸€é“é˜²çº¿ï¼šæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if os.path.exists(path) and os.path.getsize(path) > 0:
            return True

        os.makedirs(os.path.dirname(path), exist_ok=True)
        resp = requests.get(url, headers=HEADERS, verify=False, timeout=10)
        if resp.status_code == 200:
            with open(path, 'wb') as f:
                f.write(resp.content)
            return True
        return False
    except:
        return False

def worker_task(args):
    bundle_name, compressed_uuid, import_ver = args
    import_prefix = compressed_uuid[:2]
    real_uuid = decompress_uuid(compressed_uuid)

    # ============================================
    # âš¡ æé€Ÿè·³è¿‡é€»è¾‘
    # ============================================
    # åªè¦ æœ¬åœ°ç´¢å¼•é‡Œæœ‰ è¿™ä¸ª UUID (ä¸ç®¡æ˜¯é•¿è¿˜æ˜¯çŸ­)ï¼Œç›´æ¥è·³è¿‡
    if real_uuid in EXISTING_UUIDS:
        return
    if compressed_uuid in EXISTING_UUIDS:
        return
        
    # å¦‚æœç´¢å¼•æ²¡å‘½ä¸­ï¼Œå†æ£€æŸ¥ä¸€éå…·ä½“è·¯å¾„ï¼ˆåŒä¿é™©ï¼‰
    rel_path_long = f"{bundle_name}/import/{import_prefix}/{real_uuid}.{import_ver}.json"
    save_path_long = os.path.join(SAVE_IMPORT_ROOT, rel_path_long)
    if os.path.exists(save_path_long):
        return

    # ============================================
    # â¬‡ï¸ ä¸‹è½½é€»è¾‘
    # ============================================
    # ä¼˜å…ˆä¸‹è½½ é•¿ UUID æ ¼å¼
    url_long = f"{BASE_RES_URL}assets/{rel_path_long}"
    if download_file(url_long, save_path_long):
        return

    # å¤±è´¥åˆ™å°è¯• çŸ­ UUID æ ¼å¼
    rel_path_short = f"{bundle_name}/import/{import_prefix}/{compressed_uuid}.{import_ver}.json"
    save_path_short = os.path.join(SAVE_IMPORT_ROOT, rel_path_short)
    url_short = f"{BASE_RES_URL}assets/{rel_path_short}"
    download_file(url_short, save_path_short)

def parse_version_array(uuids, ver_array):
    v_map = {}
    if not ver_array: return v_map
    for i in range(0, len(ver_array), 2):
        idx = ver_array[i]
        ver = ver_array[i+1]
        if idx < len(uuids):
            v_map[uuids[idx]] = ver
    return v_map

def main():
    print("=== DMM Import æ™ºèƒ½è¡¥å…¨ä¸‹è½½å™¨ (Pre-Scan Mode) ===")
    
    # 1. å…ˆæ‰«ææœ¬åœ°å·²æœ‰ä»€ä¹ˆ
    scan_local_files()

    if not os.path.exists(LOCAL_CONFIG_DIR):
        print(f"âŒ æ‰¾ä¸åˆ°é…ç½®ç›®å½• {LOCAL_CONFIG_DIR}")
        return

    # 2. è§£æä»»åŠ¡åˆ—è¡¨
    print("[-] æ­£åœ¨è§£æ Config ç”Ÿæˆä»»åŠ¡åˆ—è¡¨...")
    config_files = []
    for root, dirs, files in os.walk(LOCAL_CONFIG_DIR):
        for f in files:
            if f.startswith("config.") and f.endswith(".json"):
                config_files.append(os.path.join(root, f))
    
    tasks = []
    skipped_count = 0
    
    # é¢„å¤„ç†ï¼šåªæŠŠã€ä¸åœ¨ã€‘EXISTING_UUIDS é‡Œçš„ä»»åŠ¡åŠ å…¥é˜Ÿåˆ—
    # è¿™æ ·è¿›åº¦æ¡å°±åªæ˜¾ç¤ºâ€œçœŸæ­£éœ€è¦ä¸‹è½½â€çš„æ•°é‡
    for cfg_path in tqdm(config_files, unit="cfg"):
        try:
            bundle_name = os.path.basename(os.path.dirname(cfg_path))
            with open(cfg_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            uuids = data.get('uuids', [])
            import_vers = parse_version_array(uuids, data.get('versions', {}).get('import', []))
            
            for uuid, ver in import_vers.items():
                real = decompress_uuid(uuid)
                # åœ¨ç”Ÿæˆä»»åŠ¡é˜¶æ®µç›´æ¥è¿‡æ»¤
                if (real in EXISTING_UUIDS) or (uuid in EXISTING_UUIDS):
                    skipped_count += 1
                else:
                    tasks.append((bundle_name, uuid, ver))
                
        except Exception:
            pass

    print(f"\nâœ… ç»Ÿè®¡ç»“æœï¼š")
    print(f"   - æœ¬åœ°å·²å­˜åœ¨ (è·³è¿‡): {skipped_count}")
    print(f"   - éœ€è¦æ–°ä¸‹è½½:       {len(tasks)}")

    if not tasks:
        print("ğŸ‰ æ‰€æœ‰æ–‡ä»¶éƒ½å·²å­˜åœ¨ï¼Œæ— éœ€ä¸‹è½½ï¼")
        return

    print("[-] å¼€å§‹ä¸‹è½½ç¼ºå¤±æ–‡ä»¶...")
    
    # 3. æ‰§è¡Œä¸‹è½½ (åªä¸‹è½½ç¼ºå¤±çš„)
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        list(tqdm(executor.map(worker_task, tasks), total=len(tasks), unit="file"))

    print("\nâœ… è¡¥å…¨å®Œæˆï¼")

if __name__ == "__main__":
    main()